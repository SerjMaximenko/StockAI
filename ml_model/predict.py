import time
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from kafka import KafkaConsumer, KafkaProducer
import json
from sklearn.preprocessing import MinMaxScaler
import os

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Kafka
KAFKA_BROKER = "localhost:9092"
INPUT_TOPIC = "market-data"
OUTPUT_TOPIC = "predictions"

SEQUENCE_LENGTH = 1

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ LSTM
class StockLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(StockLSTM, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
def load_model(symbol):
    model_path = f"models/stock_lstm_{symbol}.pth"
    if not os.path.exists(model_path):
        print(f"‚ö† –ú–æ–¥–µ–ª—å –¥–ª—è {symbol} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return None

    model = StockLSTM(input_size=5, hidden_size=500, num_layers=5, output_size=1).to(device)
    model.load_state_dict(torch.load(model_path))
    model.eval()
    return model

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Kafka
def get_latest_data():
    consumer = KafkaConsumer(
        INPUT_TOPIC,
        bootstrap_servers=KAFKA_BROKER,
        auto_offset_reset="earliest",  # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ
        enable_auto_commit=True,
        group_id="stock-predictor",
        value_deserializer=lambda m: json.loads(m.decode("utf-8")),
    )

    data = []
    timeout = 10  # –ñ–¥—ë–º –¥–∞–Ω–Ω—ã–µ 10 —Å–µ–∫—É–Ω–¥
    start_time = time.time()

    while time.time() - start_time < timeout:
        msg = consumer.poll(timeout_ms=1000)
        if msg:
            for _, record in msg.items():
                for message in record:
                    data.append(message.value)
        if len(data) >= SEQUENCE_LENGTH:
            break

    consumer.close()

    if not data:
        print("‚ö† –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ Kafka! –ü—Ä–æ–≤–µ—Ä—å `market-data`.")
        return None

    return pd.DataFrame(data)

# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏
def prepare_input(df):
    df = df.copy()
    df.sort_values("timestamp", inplace=True)
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(df[["open_price", "high_price", "low_price", "close_price", "volume"]])
    X = np.array([scaled_data])

    return torch.tensor(X, dtype=torch.float32).to(device), scaler

# –û—Ç–ø—Ä–∞–≤–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ Kafka
def send_prediction(prediction, symbol):
    producer = KafkaProducer(
        bootstrap_servers=KAFKA_BROKER,
        value_serializer=lambda v: json.dumps(v).encode("utf-8"),
    )

    message = {"symbol": symbol, "predicted_close_price": float(prediction)}
    producer.send(OUTPUT_TOPIC, value=message)
    producer.flush()
    print(f"üì° –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {message}")

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
def predict():
    print("üì° –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Kafka...")
    df = get_latest_data()
    if df is None:
        return

    symbols = df["symbol"].unique()

    for symbol in symbols:
        print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ {symbol}...")

        model = load_model(symbol)
        if model is None:
            continue

        df_symbol = df[df["symbol"] == symbol]
        print(f"üîç {symbol}: {df_symbol.shape[0]} –∑–∞–ø–∏—Å–µ–π")

        if df_symbol.shape[0] < SEQUENCE_LENGTH:
            print(f"‚ö† –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            continue

        X_input, scaler = prepare_input(df_symbol)

        with torch.no_grad():
            prediction = model(X_input).item()

        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—É—é —Ü–µ–Ω—É –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ä–µ–∞–ª—å–Ω—ã–π –º–∞—Å—à—Ç–∞–±
        prediction = scaler.inverse_transform([[0, 0, 0, prediction, 0]])[0][3]
        print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –¥–ª—è {symbol}: {prediction:.2f}")

        send_prediction(prediction, symbol)

def count_parameters(model):
    return sum(p.numel() for p in model.parameters())

if __name__ == "__main__":
    predict()
